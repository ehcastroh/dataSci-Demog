{"cells": [{"source": ["Demography 88<br>\n", "Fall 2017<br>\n", "Carl Mason (cmason@berkeley.edu)<br>\n", "\n", "# Lab 9: Mariel Boatlift(second part): Bootstrapping the differences\n", "\n", "In last week's lab, you mastered the CPS, the Miami labor market of the early 1980s, and the intricacies of computing weighted averages of grouped data. This week, we'll pick up where we left off and attempt to extend David Card's work in measuring the effect of the Mariel Boatlift on pre-boatlift Miamians. Our main tool for this will be the bootstrap, and our main contribution to science will be to search among carefully defined subgroups of the population, for those whose labor market experiences were negatively affected by the arrival of the Mariel Cubans.\n", "\n", "To help us develop clearly defined subsets of the labor force, we'll start by investigating some of the variables in Merged Outgoing Rotation Groups (morg) dataset that we have not looked at yet.\n", "\n", "After examining morg,  We'll  build a template for computing a difference in difference statistic using the wtdMean() function --which we'll use with a bootstrap simulation. \n", "\n", "Finally, you'll be turned loose to develop and test your own hypotheses.\n", "\n", "\n", "\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["# Run this cell to import the stuff we'll need\n", "import pandas as pd\n", "import numpy as np\n", "import scipy as sp\n", "import matplotlib.pyplot as plt \n", "plt.style.use('fivethirtyeight')\n", "\n", "%matplotlib inline\n", "from datascience import Table\n", "from datascience.predicates import are\n", "from datascience.util import *\n", "\n", "from IPython.display import HTML, IFrame, display\n", "datasite=\"http://courses.demog.berkeley.edu/mason88/data/\"\n", "quizsite=\"http://courses.demog.berkeley.edu/mason88/cgi-bin/quiz.py\"\n", "  \n", "def cquiz(qno) : \n", "    import IPython, requests \n", "    try:\n", "        sid\n", "    except NameError: \n", "        print(\"HEY! did you enter your sid way up at the top of this notebook?\")\n", "    Linkit='{0}?qno={1}&sid={2}'.format(quizsite,qno,sid)\n", "    #print(Linkit)\n", "    html = requests.get(Linkit)\n", "    #display(IFrame(Linkit, 1000, 300))\n", "    display(IFrame(Linkit, 1000, 400))\n", "\n", "\n", "    \n", "######################\n", "# Here it is ... the obvious place to put your student id\n", "sid=\"\"\n", "######################\n", "if sid == \"\" :\n", "    print(\"HEY! didn't I tell you to put your sid in the obvious place\")\n", " \n"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## With whom are you working on this lab?"], "metadata": {}, "cell_type": "markdown"}, {"source": ["cquiz('mariel1-partners')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## Read the data"], "metadata": {}, "cell_type": "markdown"}, {"source": ["# Read the data -- \"morg\" stands of \"merged outgoing rotation groups\" which are a subset of the data collected in \n", "# Current Population Survey\n", "\n", "morg=Table.read_table(datasite+\"morgClean.csv\")\n", "\n", "# and add the variable lnWage for log of hourly wage\n", "morg=morg.with_column('lnWage',np.log(morg['Earnhr']))\n", "# and we're going to need an indicator varialbe for Miami of course\n", "morg.append_column('Miami',[smsa == 'Miami' for smsa in morg['SMSA']])\n", "# changing NAs to 0 so that unemployed people enter computations as wage 0\n", "morg.with_column('Earnhr',[ Earnhr if ~np.isnan(Earnhr) else 0 for Earnhr in morg['Earnhr']])\n"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["# The morg dataset up close\n", "\n", "The next cell provides a list of the variables contained in morgClean.csv.  A couple of things to notice:\n", "1. Variables whose names begin with an upper case letter are variables that your instructor created -- either according to explanations found in Professor Card's paper, or b applying common sense\n", "2. Most of these variables are coded as integers where the integers which represent categorical information. Some sketchy documentation is available from NBER at http://www.nber.org/ftppub/cpsx/cpsx.pdf "], "metadata": {}, "cell_type": "markdown"}, {"source": ["# a list of all the variables in the dataset\n", "list(morg)"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["# by default .stats() does NOT do a great job with missing values  \n", "# plain old .stats ,as in\n", "# morg.select(['age','sex','Earnhr']).stats()\n", "# will produce an ominous warning message because \n", "print(\"There are {0} missing values in Earnhr\".format((np.sum(np.isnan(morg['Earnhr'])))))\n", "\n", "# but .stats() is flexibile -- any function that takes an np array can be substituted for the defaults\n", "# by simply listing them.  \n", "#  Because it's python, we can also write our own functions to pass to the .stat() method.  For example\n", "#  it's nice to know how many NON missing observations we have\n", "def nonMiss(x):\n", "    '''\n", "    returns the number of observations which are not coded as nan\n", "    '''\n", "    return(np.sum(~np.isnan(x)))\n", "morg.select(['age','sex','Earnhr']).stats((np.nanmin,np.nanmax,np.nanmean,np.nanmedian,len,nonMiss))\n", "#NOTE the extra '()'  .stats() expects a tuple of function names, more than one function is required"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## Summary statistics\n", "For continuous or integer variables, the .stats() method is a handy way of exploring the data set\n", "when combined with .where() and .select() one can get specific about population subgroups.\n"], "metadata": {}, "cell_type": "markdown"}, {"source": [], "metadata": {}, "cell_type": "markdown"}, {"source": ["cquiz('mariel1-11')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## For categorical data and for breaking things up into groups.. the .pivot() method is your friend\n", "\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["## a simple .pivot() to look counts of observations by year and 'classer'\n", "## BUT NO ... this one does not work well\n", "##morg.pivot('year','classer').show()\n", "## apparently, having too many nan's in a column causes problems\n", "\n", "## this works better\n", "morg.where(~np.isnan(morg['classer'])).pivot('EthRace','classer').show()\n", "#  And a fancier one that finds the percentage of observed workers (unweighted) who are black\n", "#  in the various employment classes across time\n", "\n", "morg.with_column('black',morg['EthRace']=='NonHisp:black').where(~np.isnan(morg['classer'])).pivot('year','classer',values='black',collect=np.nanmean)"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["##  Hopefully, you are curious about what the \"classer\" variable means...\n", "\n", "There are several places where you might find information about the variable in the CPS (the data set that we have been using). Here is convenient one : http://www.nber.org/morg/annual/desc/morg79/desc.txt -- you'll need to\n", "use your browsers search function to navigate in it -- it first lists the variables, but deeper in file it tells what each category means.\n", "\n", "##### The next question asks you about Less Skilled Service Workers. Your instinct should be to go to the above document and try to find a variable related to skills or occupation.  While this is excellent intuition, in this particular case it will not be rewarded because the variable Occupation, which holds the information that you are interested in was constructed by your instructor NOT by the CPS.  It follows the caption in Card's Table 1 -- and also Card's computer programs.  The variable is a cleaned and simplified version of the docc70 variable which gives broad occupational categories.\n", "(Recall that the variables with upper case letters are constructed) \n", "\n", "The gist:  You'll need to use the variable \"Occupation\" to answer the next question.\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["## Another question for you\n", "execute and click below as usual."], "metadata": {}, "cell_type": "markdown"}, {"source": ["cquiz('mariel1-12')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["# The wtdMean() function from last week\n", "\n", "What we did above, of course, neglects the sample weights.  In order to publish in a serious journal,\n", "we'll have to do a little better.  Let's pick up where we left off with the wtdMean() function."], "metadata": {}, "cell_type": "markdown"}, {"source": ["## This is the same wtdMean function that we developed in the first Mariel Boatlift lab\n", "def wtdMean(data,depvar,gvars=['Miami','year'],wvar='Earnwt'):\n", "\n", "    \"\"\"\n", "    Exepcts:\n", "    1) data: dataset (generally morg or morg.where(...));\n", "    2) depvar: a dependent variable column e.g. lnWage; \n", "    3) gvars: a list of variables by which to group the data,\n", "    and \n", "    4) wvar: a column of weights(Earnwt by default)\n", "    returns a table with one row for each unique combination of gvars along  the corresponding\n", "    weighted mean of depvar\n", "    \"\"\"\n", "    # creat a list of column names of the input data that we need; we'll discard unused columns\n", "    # note that we need to copy rather than asign here as we still need gvars\n", "    allvars=gvars.copy()\n", "    allvars.append(depvar)\n", "    allvars.append(wvar)\n", "    #get rid of columns we don't need\n", "    dset=data.select(allvars)\n", "    #get rid of rows that we don't want -- especially missing values\n", "    dset=dset.where(~np.isnan(dset[wvar]))\n", "    dset=dset.where(~np.isnan(dset[depvar]))\n", "    # compute the numerator and denominator\n", "    dset.append_column(depvar+'WTD',dset[depvar]*dset[wvar])\n", "    result=dset.groups(gvars,collect=np.nansum)\n", "    # and do the division\n", "    result.append_column(depvar+\"WTDmean\",result[depvar+ 'WTD'' nansum']/result[wvar+' nansum'])\n", "    # return the result tossing out some intermediate calcultions\n", "    return(result.drop([depvar+\" nansum\",depvar+\"WTD\"+\" nansum\"]))"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}, {"source": ["## Use the wtdMean function to compute a table of weighted means of earnings by Occupation and EthRace.\n", "\n", "Recall the Occupation codes observations by broad categories of work.  We may wish to use these categories in our bootstrap statistics, so let's take a closer look but investigating the pattern of earnings across Occupation and EthRace."], "metadata": {}, "cell_type": "markdown"}, {"source": ["## Let's use the wtdMean() function to further explore the data set.\n", "\n", "## How about mean wages by EthRace and Occupation \n", "\n", "## we'll include only those in the labor force employed + unemployed\n", "OccEthTab=wtdMean(morg.where('Labf',True),depvar=???,gvars=???,wvar='Earnwt')\n", "\n", "\n", "## easier to see if we use the pivot-table the thing\n", "OccEthTab.pivot('EthRace','Occupation',values='EarnhrWTDmean',collect=np.array)"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["cquiz('mariel1-10')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["# A statistic that captures the difference between wages in Miami and the control cities.\n", "\n", "We observed in the first Mariel Boatlift lab, that there are persistent differences between wages in Miami and the control cities.  This sort of pattern is what the diff-in-diffs technique is designed to handle.  Because we have a control group of cities -- that did not experience the influx of Marileitos,  what we want to measure is the extent to which the *difference* between wages in Miami and wages in the control cities was *changed* between the time before the Marielitos arrived and a few years later.\n", "\n", "This should remind you at least a little bit of the lab we did two weeks ago, on the trajectory of wages of immigrants vs non-immigrants at different ages. We're going to take the same computational approach in this lab as we did in that one.\n", "\n", "\n", "\n", "\n", "## Let's discuss how to frame the problem\n", "\n", "It will be helpful to draw a plot similar to those that we created last week\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["# Let's call this cell the \"Original wageTab Cell\"\n", "# A table of weighted mean wages for Miami vs Control towns 1979-1985\n", "## and a familliar looking plot of the two average earnings trajectories.\n", "WageTab=wtdMean(morg.where('Labf',True),'Earnhr',gvars=['Miami','year'])\n", "WageTab.show()\n", "WageTab.scatter('year','EarnhrWTDmean',colors='Miami')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## Framing the problem (cont)\n", "\n", "In the above graph, we have 8 quantities from which we'll assemble as *statistic*.  Is this sounding familiar or what!\n", "\n", "There are many ways that we could do this. What we seek is a *difference* between Miami and the control group in 1979 and then a corresponding difference at some point *after* the boatlift.\n", "\n", "## The quantity of interest is not one cell of this table but rather a function of a few cells.\n", "\n", "In particular,  consider the quantity:$ (w_{C,1982}-w_{C,1979})-(w_{M,1982}-w_{M,1979})$ where $w$ are weighted mean wages, $C$ refers to combined data from all of the control cities, $M$ refers to Miami and four digit numbers like 1979 are years.\n", "\n", "This quantity is known  as a \"difference in differences\" statistic--because that is what it is.  The difference between the difference  between wages in 1979 and 1982 in Miami an the Control.\n", "\n", "#### It's a sensible quantity for us to work with if we believe that the question at hand is whether or not an influx of immigrants into Miami (but not the control cities) should have lead to decrease in wages in Miami -- relative to what they **would** have been had the influx not occurred (and thus had Miami's economy developed in the same way as the other cities.  In a sense, this \"diff-in-diff\" construct removes the effects of everything that's different about Miami and the control cities *but does not change over the time period in question*. \n", "\n", "\n", "\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["def diffStat(WageTab,EndYear=1982,depVar='EarnhrWTDmean') :\n", "    \"\"\"\n", "    Expectes WageTab - table created by wtdMean, must include Miami and year among 'gvars' \n", "    depVar could be any numerical column, of WageTab, Returns a diff in diffs statistic'\n", "    for Miami v control cities 1979- EndYear\n", "    \"\"\"\n", "    # Using WageTab we can construct our diff-in-diff statistic like this\n", "    wM2=(WageTab.where('Miami',True).where('year',EndYear))[depVar]\n", "    wM1=(WageTab.where('Miami',True).where('year',1979))[depVar]\n", "    wC2= ???\n", "    wC1= ???\n", "    return((wC2-wC1)-(wM2-wM1))\n", "diffStat(WageTab,EndYear=1982)"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["cquiz('mariel1-121') "], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## So we have a statistic, what could possibly make us happier?\n", "\n", "#### How about  a *different* statistic?\n", "\n", "Our current version of the diff-in-diffs statistic will work for our purposes, but it is NOT the *only* statistic that could do this job, and as presently implemented, it is probably not the best.\n", "\n", "1.  Why 1982 rather than 1983 or 1984 or even 1900 -- we know that in the long run, lots of things could adjust and thereby reduce the effect, but when does the short run end?\n", "1. Why not some other cities in the control group -- or perhaps the whole US?  Hard to say, Card chose cities that he thought were similar to Miami, Suro might argue that Miami is unique.  The best we can do here is probably to remind ourselves that the strength of this analysis rests on the magnitude of the \"natural experiment\": with a sudden and unexpected increase in labor supply of the the magnitude of the Mariel Boatlift, there *should* be plenty of evidence of wage impacts if indeed there were wage impacts.  \n", "1.  As currently formulated -- with wageTab from the \"Original wageTab cell\", our diff-in-diff statistic looks at the mean wage of all workers in the labor force... is this wise?\n", "\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["cquiz('mariel1-122')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## Using the bootstrap with the 'diff-in-diffs' statistic -- \n", "\n", "Putting aside *for the moment* the question of what is the appropriate set of workers to consider in assessing the effect of immigration on wages,  let's turn to the mechanics of the bootstrap."], "metadata": {}, "cell_type": "markdown"}, {"source": ["## Step by step template for bootstrapping the diff-in-diffs statistic\n", "\n", "\n", "\n", "1. Construct the \"original sample\"  in this case it is not simply morg\n", "1. Repeat a large number of times:\n", "    1. draw bootstrap resample from original sample\n", "    1. compute bootstrap statistic and store in array\n", "1. display and interpret results"], "metadata": {}, "cell_type": "markdown"}, {"source": ["## Step 1 construct the original sample\n", "\n", "Remember that we are only comparing Earnings in 1979 with those in 1982 the rest of the years, for now at least, we are going to ignore. Consequently, the \"original sample\" for this exercise is not the complete morg.\n", "\n", "HINT: your instructor expects to find 2315 observations in Miami and 19870 in the control cities"], "metadata": {}, "cell_type": "markdown"}, {"source": ["original_sample=morg.where('year',1979).append(morg.where('year',???)).where('Labf',???)\n", "print(\"\"\"\n", "number of observations in Miami: {0}\n", "number of observations in control towns: {1}\"\"\".format(original_sample.where('Miami',True).num_rows,\n", "                                                      original_sample.where('Miami',False).num_rows))"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}, {"source": ["## Step 2  drawing bootstrap samples\n", "\n", "Let's set up the code to draw one set of random resamples"], "metadata": {}, "cell_type": "markdown"}, {"source": ["# Let's call this cell \"the cell wherein we resample\"\n", "np.random.seed(13531)  # this is TEMPORARY \n", "print(\"don't forget to comment out np.random.seed when doing bootstrap for real\")\n", "bs_sample_M79=original_sample.where('Miami',True).where('year',1979).sample()\n", "bs_sample_M82=original_sample.where('Miami',True).where('year',1982).sample()\n", "bs_sample_C79=original_sample.where('Miami',False).where('year',1979).sample()\n", "bs_sample_C82=original_sample.where('Miami',False).where('year',1982).sample()"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["cquiz('mariel1-123')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## Step 3 compute bootstrap statistic from bootstrap sample\n", "\n", "Hint: with np.random.seed(13531) set in the \"Cell Wherein We Resample\", the bootstrap resampled statistic should be  0.140002]\n", "\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["bs_sample=bs_sample_M79.append(bs_sample_M82).append(bs_sample_C79).append(bs_sample_C82)\n", "bs_WageTab=wtdMean(???,depvar='???',gvars=[???,???])\n", "bs_statistic=diffStat(???,EndYear=???,depVar='EarnhrWTDmean')\n", "bs_statistic"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## Assemble the package\n", "\n", "Now let's put all this code together into a single function that runs a user specified number of trials (resamples); computes the bootstrap statistic for each trial; and returns an np.array of bootstrap statistics from which we may derive profound truths.\n", "\n", "HINT: with random.seed(13531) the function should produce the familiar value of  0.140002 as the first element of the list of 'BSresults' returned."], "metadata": {}, "cell_type": "markdown"}, {"source": ["\n", "\n", "# step 1 happens outside the function -- create the original sampe\n", "original_sample=morg.where('year',???).append(morg.where('year',???)).where('Labf',???)\n", "def bootstrap_statistic(original_sample, replications=10):\n", "    \"\"\"Returns an array of bootstrap-simulated statistics\n", "    original_sample: table containing the original sample\n", "    replications: number of bootstrap samples\n", "    \"\"\"\n", "    #just_one_column = original_sample.select(label)\n", "    BSresults = make_array()\n", "    np.random.seed(13531)\n", "    print(\"heads up: is random seed set?\")\n", "    for i in np.arange(replications):\n", "        #  step 2 -- draw bootstrap resamples\n", "        ???\n", "        ???\n", "        ???\n", "        ???\n", "        bootstrap_sample=bs_sample_M79.append(bs_sample_M82).append(bs_sample_C79).append(bs_sample_C82)\n", "        \n", "        # step 3 -- compute resampled bootstrap statistic and append to BSresults\n", "        \n", "            \n", "        bs_WageTab= ??? \n", "        \n", "        resampled_statistic=???\n", "        BSresults = np.append(BSresults, resampled_statistic)\n", "\n", "    return BSresults\n", "\n", "bootstrap_statistic(original_sample,replications=2)\n", "\n"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## Now the science...\n", "\n", "in the following 3 cells, we will run 100 bootstrap trials then draw some graphs that will help us interpret them.\n", "leave the random seed set for now so we can compare results -- but don't forget about it completely."], "metadata": {}, "cell_type": "markdown"}, {"source": ["#original_sample=morg.where('year',1979).append(morg.where('year',1982)).where('Labf',True)\n", "dINd=bootstrap_statistic(original_sample,100)"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["## there might be an easier way to plot this with datacience.Table  but I'm using\n", "## pyplot here because I can.\n", "def histDnD(dINd):\n", "    \"\"\"\n", "    draws a historgram along with 95% confidence bounds. Expects an np.array -- or a column of\n", "    a table but NOT a table\n", "    \"\"\"\n", "    plt.figure()\n", "    plt.hist(dINd)\n", "    plt.title(\"Histogram of 95 % confidence \")\n", "    p05=Table().with_column('dind',dINd).percentile(2.5)['dind'][0]\n", "    p95=Table().with_column('dind',dINd).percentile(97.5)['dind'][0]\n", "    plt.axvline(x=p05,color='red',linewidth=1)\n", "    plt.axvline(x=p95,color='red',linewidth=1)\n", "histDnD(dINd)    "], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["def cdfDnD(dINd) :\n", "    \"\"\"\n", "    expects an np.array or column of a table containing bootstrap resampled statistics\n", "    produces a CDF\n", "    \"\"\"\n", "    dINd.sort()\n", "    plt.plot(dINd,np.arange(len(dINd))/len(dINd),linestyle='-',linewidth=2,color='black')\n", "    plt.title(\"CDF of dif in difs\")\n", "    dtab=Table().with_column('dind',dINd)\n", "    plt.axvline(dtab.percentile(2.5)[0],linestyle=':',linewidth=2,color='blue')\n", "    plt.axhline(.025,linestyle=':',linewidth=2,color='blue')\n", "    plt.axvline(dtab.percentile(97.5)[0],linestyle=':',linewidth=2,color='gold')\n", "    plt.axhline(.975,linestyle=':',linewidth=2,color='gold')\n", "\n", "    \n", "cdfDnD(dINd)    "], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["cquiz('mariel1-124')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["cquiz('mariel1-125')"], "execution_count": null, "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["# In the final segment of this lab,  *you* generate a hypothesis about the effect of the Mariel Boatlift on the Miami labor market ... and test it.\n", "\n", "You are now an expert in the Miami labor market circa 1980 and in construction of bootstrap estimates of confidence bounds around difference in differences statistics.  Congratulations.   The final step of this process  skills that are complementary to their own.  \n", "\n", "Well, now it's later.\n", "\n", "The final segment of this lab comes down to defining subset X of the Miami Labor market in such a way as to be likely to find an effect -- if there is one.  In other words, devise a group of Miami workers in 1979 for whom the <i>Marielitos</i> were likely to be either substitutes OR complements. In other words a group whose wages would be most likely to either rise or fall as a result of the influx of low skilled migrants.  Then write the code necessary to bootstrap it at least 100 times.\n", "\n", "The variables that you have to work with are:\n", "1. Age\n", "2. EthRace -- but note that there are too few Cubans in the other cities to make this work.\n", "3. Education\n", "4. Sex\n", "5. Occupation\n", "6. SelfEmployment, private sector, public sector\n", "\n", "NOTE:\n", "\n", "1. The dependent variable, presently Earnhr, is a good choice, but so night be the unemployment rate\n", "1. There are not enough Cubans in the control cities to get an estimate so your group cannot be made up exclusively of Cubans.\n", "1. 1979 has to be the start year,  but what you choose for your end point is up to you.\n", "\n", "## Next week in class, you will present your results to the class.\n", "#### No worries presentations will be brief and stress free... as long as you have completed the exercise.\n", "\n", "In order that we have some variety in our presentations, you'll need to post your group definition to a google doc.\n", "\n", "Hypotheses are first come first served so get to the google doc first to stake your scientific claim.  \n", "\n", "\n", "https://docs.google.com/a/berkeley.edu/spreadsheets/d/1L905sFMexxC-iMU24-RjyFzhFaF9lR47dgsDDJambyI/edit?usp=sharing\n", "\n", "Don't worry *too* much about the presentation -- just be prepared to answer four questions:\n", "\n", "1. What is your subgroup of interest ?\n", "1. What is your null hypothesis ?\n", "1. What is the value of your statistic (on the original sample) ?\n", "1. What is the 95 percent confidence interval of your statistic ?"], "metadata": {}, "cell_type": "markdown"}, {"source": [], "metadata": {}, "cell_type": "markdown"}, {"source": ["## devise a statistic; code and run the bootstrap with at least 100 trials"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}, {"source": ["## Please evaluate this lab and remember to answer the question on the reading for next week."], "metadata": {}, "cell_type": "markdown"}, {"source": ["cquiz('mariel1-eval')"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}, {"source": ["## The reading for next week is a critique of all that we have been doing for the last two weeks.\n", "cquiz('borjas')"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}], "metadata": {"language_info": {"mimetype": "text/x-python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.1"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 2}